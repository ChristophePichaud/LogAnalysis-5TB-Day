# LogAnalysis-5TB-Day

## üöÄ Quick Start

**Nouveau?** Commencez par le **[Executive Summary](./EXECUTIVE-SUMMARY.md)** (5 minutes de lecture) pour une vue d'ensemble rapide de la solution, des co√ªts et du ROI.

## Vue d'ensemble

Ce repository contient l'architecture et la documentation pour une solution d'analyse de **5 TB de logs par jour** en utilisant **Azure Data Explorer (ADX)** avec le langage de requ√™te **KQL (Kusto Query Language)**.

## üìã Contenu de la Documentation

### ‚ö° Executive Summary

#### [Executive Summary](./EXECUTIVE-SUMMARY.md) ‚≠ê **START HERE**
R√©sum√© ex√©cutif de 5 minutes avec:
- Solution recommand√©e et justification
- Co√ªts r√©sum√©s (4 sc√©narios)
- Architecture simplifi√©e
- ROI et b√©n√©fices
- Comparaison alternatives
- Quick start en 30 minutes

### üìê Architecture

#### [Architecture Globale](./architecture.md)
Document principal d√©crivant l'architecture compl√®te de la solution:
- Vue d'ensemble et objectifs
- Composants principaux (ADX, Event Hubs, Storage)
- Strat√©gies de d√©ploiement et s√©curit√©
- Haute disponibilit√© et disaster recovery
- Monitoring et optimisations

#### [Solution Technique ADX](./adx-solution.md)
D√©tails techniques approfondis sur Azure Data Explorer:
- Pourquoi ADX pour l'analyse de logs
- Architecture d√©taill√©e du cluster
- Configuration et sizing (8-10 n≈ìuds E16s_v5)
- Sch√©mas de tables optimis√©s
- Materialized views et update policies
- Best practices et cas d'usage r√©els

### üîÑ Ingestion de Donn√©es

#### [Strat√©gie d'Ingestion](./data-ingestion.md)
Guide complet sur l'ingestion de 5TB/jour:
- **Option 1**: Azure Event Hubs (Streaming) - Recommand√©
  - Latence < 2 minutes
  - Configuration 32+ partitions
- **Option 2**: Azure Blob Storage (Batch)
  - Co√ªt r√©duit
  - Latence 5-15 minutes
- **Option 3**: Hybrid (Streaming + Batch)
- Transformation et enrichissement avec Update Policies
- Monitoring et troubleshooting

### üìä Requ√™tes et Analyse

#### [Exemples KQL](./kql-examples.md)
Collection compl√®te de requ√™tes KQL pour l'analyse de logs:
- Analyses de base (comptages, filtres)
- Analyse temporelle et time series
- Performance et latence
- Analyse d'erreurs et troubleshooting
- S√©curit√© et audit
- Distributed tracing multi-service
- Analytics business
- Monitoring et alerting
- Fonctions personnalis√©es et best practices

### üí∞ Estimation Financi√®re

#### [Estimation de Co√ªts](./cost-estimation.md)
Analyse d√©taill√©e des co√ªts (Step 2):
- **Co√ªt mensuel baseline**: $15,000-20,000 (~$180,000-240,000/an)
- **Co√ªt optimis√© avec RI**: $13,000-15,000 (~$156,000-180,000/an)
- D√©tail par composant (ADX, Event Hubs, Storage, Network)
- 3 sc√©narios: Production Optimis√©e, Startup, Enterprise HA
- Strat√©gies d'optimisation (Reserved Instances, Tiered Storage)
- Comparaison avec alternatives (Elasticsearch, Splunk, Datadog)
- ROI et justification business

### üé® Diagrammes d'Architecture

#### [Diagrammes PUML](./diagrams/)
Diagrammes PlantUML pour visualiser l'architecture:

1. **[architecture-overview.puml](./diagrams/architecture-overview.puml)**
   - Vue d'ensemble compl√®te de la solution
   - Sources ‚Üí Collection ‚Üí Ingestion ‚Üí ADX ‚Üí Consommation
   - S√©curit√©, monitoring, DR

2. **[data-flow.puml](./diagrams/data-flow.puml)**
   - Flux de donn√©es d√©taill√© end-to-end
   - S√©quence d'ingestion avec timings
   - 5 √©tapes: G√©n√©ration ‚Üí Collection ‚Üí Transport ‚Üí Ingestion ‚Üí Query

3. **[adx-cluster.puml](./diagrams/adx-cluster.puml)**
   - Architecture interne du cluster ADX
   - Engine nodes, storage tiers, data management
   - Sp√©cifications techniques par n≈ìud

**Pour g√©n√©rer les images PNG** depuis les fichiers PUML:
```bash
# Installation PlantUML
brew install plantuml  # macOS
# ou
sudo apt install plantuml  # Ubuntu

# G√©n√©ration des diagrammes
plantuml diagrams/*.puml
```

## üéØ Solution Propos√©e

### Architecture Recommand√©e

**Cluster Azure Data Explorer**:
- **8 n≈ìuds** Standard_E16s_v5 (16 cores, 128GB RAM, 512GB SSD)
- **Capacit√© d'ingestion**: 1,600 GB/h (marge pour peaks 3x)
- **Hot cache**: 4 TB SSD (7-14 jours)
- **Hot storage**: 90 jours (~4.5 TB compress√©)
- **Cold storage**: 1-2 ans (Azure Blob Cool Tier)

**Ingestion via Event Hubs**:
- **32 partitions** pour parall√©lisme
- **10-20 Throughput Units** avec auto-inflate
- **Latence**: < 2 minutes end-to-end
- **Format**: JSON compress√© (GZip) ou Parquet

**Performance**:
- **Requ√™tes**: Sub-seconde sur milliards d'√©v√©nements
- **Compression**: Ratio 10:1 (5TB ‚Üí 500GB stock√©)
- **SLA**: 99.9% (99.99% avec multi-r√©gion)

### M√©triques Cl√©s

| M√©trique | Valeur |
|----------|--------|
| Volume quotidien | 5 TB |
| D√©bit moyen | 208 GB/h (~58 MB/s) |
| D√©bit peak (3x) | 625 GB/h |
| Latence ingestion | < 2 minutes |
| Latence query (hot cache) | < 500ms |
| Compression ratio | 10:1 |
| R√©tention hot | 90 jours |
| R√©tention cold | 1-2 ans |

### Co√ªts Estim√©s

| Sc√©nario | Mensuel | Annuel |
|----------|--------:|-------:|
| **Baseline (sans optimisations)** | $20,340 | $244,080 |
| **Production Standard** | $15,291 | $183,492 |
| **Optimis√© (RI 3 ans)** | $13,465 | $161,580 |
| **Startup Minimal** | $5,000 | $60,000 |
| **Enterprise HA Multi-r√©gion** | $17,273 | $207,276 |

## üöÄ D√©marrage Rapide

### Pr√©requis
- Subscription Azure
- Azure CLI install√©
- Permissions pour cr√©er ressources (Contributor role minimum)

### √âtape 1: Cr√©er le Cluster ADX

```bash
# Variables
RG="rg-loganalysis-prod"
LOCATION="westeurope"
CLUSTER_NAME="loganalysis-prod-adx"

# Cr√©er resource group
az group create --name $RG --location $LOCATION

# Cr√©er cluster ADX
az kusto cluster create \
  --cluster-name $CLUSTER_NAME \
  --resource-group $RG \
  --location $LOCATION \
  --sku Standard_E16s_v5 \
  --capacity 8 \
  --enable-streaming-ingest true \
  --zones "1,2,3"
```

### √âtape 2: Cr√©er Event Hub

```bash
# Event Hub Namespace
az eventhubs namespace create \
  --name "loganalysis-prod-eh" \
  --resource-group $RG \
  --location $LOCATION \
  --sku Standard \
  --enable-auto-inflate true \
  --maximum-throughput-units 20

# Event Hub
az eventhubs eventhub create \
  --name "application-logs" \
  --namespace-name "loganalysis-prod-eh" \
  --partition-count 32 \
  --message-retention 1
```

### √âtape 3: Configurer ADX Database et Tables

Se r√©f√©rer √† [adx-solution.md](./adx-solution.md) section "Configuration D√©taill√©e" pour:
- Cr√©ation de database
- D√©finition du sch√©ma de table
- Ingestion mapping
- Data connection vers Event Hub

### √âtape 4: D√©ployer Agents de Collecte

Se r√©f√©rer √† [data-ingestion.md](./data-ingestion.md) section "Configuration des Agents" pour:
- Fluentd configuration
- Vector configuration
- Routage et buffering

## üìö Ressources

### Documentation Officielle
- [Azure Data Explorer](https://docs.microsoft.com/azure/data-explorer/)
- [KQL Reference](https://docs.microsoft.com/azure/data-explorer/kql-quick-reference)
- [Event Hubs Documentation](https://docs.microsoft.com/azure/event-hubs/)

### Outils
- [ADX Web UI](https://dataexplorer.azure.com/)
- [Azure Pricing Calculator](https://azure.microsoft.com/pricing/calculator/)
- [KQL Playground](https://dataexplorer.azure.com/clusters/help/databases/Samples)

### Tutoriels
- [ADX Best Practices](https://docs.microsoft.com/azure/data-explorer/best-practices)
- [Ingestion Best Practices](https://docs.microsoft.com/azure/data-explorer/ingest-data-overview)
- [Query Best Practices](https://docs.microsoft.com/azure/data-explorer/kusto/query/best-practices)

## ü§ù Contributions

Ce repository est un document d'architecture. Pour des questions ou suggestions:
- Ouvrir une issue
- Proposer des am√©liorations via PR
- Contacter l'√©quipe Platform Engineering

## üìù Licence

Documentation sous licence MIT - voir fichier LICENSE

## ‚úÖ Checklist de Mise en ≈íuvre

### Phase 1: Foundation (Mois 1-2)
- [ ] Provisionner cluster ADX
- [ ] Configurer Event Hub ou Blob Storage
- [ ] Cr√©er databases et tables
- [ ] Setup ingestion mappings
- [ ] Tester ingestion end-to-end
- [ ] Configurer monitoring de base

### Phase 2: Optimisation (Mois 3-4)
- [ ] Impl√©menter Update Policies
- [ ] Cr√©er Materialized Views
- [ ] Optimiser hot cache policy
- [ ] Setup dashboards (Power BI/Grafana)
- [ ] Configurer alertes critiques
- [ ] Documenter runbooks

### Phase 3: Scaling (Mois 5-6)
- [ ] Acheter Reserved Instances
- [ ] Impl√©menter tiered storage
- [ ] Setup follower database (DR)
- [ ] Optimiser query performance
- [ ] Activer auto-scaling
- [ ] Audit de co√ªts

### Phase 4: Excellence (Mois 7+)
- [ ] ML pour anomaly detection
- [ ] Self-service analytics
- [ ] Advanced security (RLS)
- [ ] Multi-tenant isolation
- [ ] Continuous optimization

## üìä Statut du Projet

**Step 1**: ‚úÖ **Compl√©t√©** - Documentation Azure Data Explorer avec KQL
- Architecture globale
- Solution technique d√©taill√©e
- Exemples KQL complets
- Strat√©gie d'ingestion
- Diagrammes PUML

**Step 2**: ‚úÖ **Compl√©t√©** - Estimation financi√®re
- Co√ªts d√©taill√©s par composant
- 3 sc√©narios (Baseline, Optimis√©, Enterprise)
- Comparaison avec alternatives
- Strat√©gies d'optimisation
- ROI et justification

---

**Version**: 1.0  
**Date**: Juin 2024  
**Auteur**: Architecture Team# Architecture Globale - Analyse de Logs 5TB/Jour

## Vue d'ensemble

Cette architecture d√©crit une solution compl√®te pour l'analyse de **5 TB de logs par jour** en utilisant Azure Data Explorer (ADX), une plateforme hautement optimis√©e pour l'analyse de donn√©es massives en temps r√©el.

## Contexte et Objectifs

### Contexte
- **Volume quotidien**: 5 TB de fichiers de logs
- **Besoin**: Analyse rapide, requ√™tes complexes, et visualisation
- **√âchelle**: ~1.8 PB par an
- **Exigences**: Ingestion en temps quasi-r√©el, r√©tention flexible, performances √©lev√©es

### Objectifs de la Solution
1. **Performance**: Requ√™tes sub-secondes sur des milliards d'√©v√©nements
2. **Scalabilit√©**: Supporter 5TB/jour avec possibilit√© d'√©volution
3. **Disponibilit√©**: SLA 99.9% minimum
4. **Co√ªt-efficacit√©**: Optimisation des co√ªts de stockage et compute
5. **Facilit√© d'utilisation**: Interface KQL intuitive pour les analystes

## Composants Principaux

### 1. Azure Data Explorer (ADX) - C≈ìur de la Solution

**Caract√©ristiques cl√©s**:
- Moteur de requ√™te distribu√© optimis√© pour l'analyse de logs
- Compression native (~10:1 en moyenne)
- Indexation automatique de toutes les colonnes
- Support natif du format JSON, CSV, Parquet, Avro

**Configuration recommand√©e**:
- **Cluster**: Type Engine Standard_E16s_v5+
- **Nombre de n≈ìuds**: 6-10 n≈ìuds (√©volutif selon charge)
- **Capacit√© d'ingestion**: ~200-250 GB/heure/n≈ìud
- **Cache SSD**: Donn√©es chaudes (7-30 jours)
- **Stockage froid**: Azure Blob Storage pour archives

### 2. Couche d'Ingestion

**Options d'ingestion**:

#### Option A: Azure Event Hubs (Recommand√© pour streaming)
- **D√©bit**: Jusqu'√† 1 GB/sec par partition
- **Partitions**: 32 partitions minimum pour 5TB/jour
- **R√©tention**: 1-7 jours dans Event Hub
- **Avantages**: Faible latence, d√©couplage, buffer automatique

#### Option B: Azure Storage (Batch)
- **Pattern**: Drop de fichiers dans Blob Storage
- **Event Grid**: Notification automatique vers ADX
- **Format**: Compressed JSON, Parquet recommand√©
- **Avantages**: Simple, √©conomique pour batch

#### Option C: Hybrid
- Streaming pour logs critiques via Event Hubs
- Batch pour logs historiques via Storage

### 3. Transformation et Enrichissement

**Update Policy dans ADX**:
```kql
// Politique de mise √† jour pour enrichissement automatique
.create-or-alter function EnrichLogs() {
    RawLogs
    | extend 
        ParsedTimestamp = todatetime(timestamp),
        Severity = case(
            level == "error", "High",
            level == "warning", "Medium",
            "Low"
        ),
        Region = extract(@"region=([^,]+)", 1, metadata)
    | project-away raw_field
}
```

### 4. Stockage Hi√©rarchis√©

**Strat√©gie de r√©tention**:
- **Hot Cache (SSD)**: 7-14 jours - Requ√™tes ultra-rapides
- **Hot Storage**: 90 jours - Performance optimale
- **Cold Storage**: 1-2 ans - Co√ªt r√©duit, acc√®s occasionnel
- **Archive**: > 2 ans - Export vers Azure Archive Storage

### 5. S√©curit√© et Conformit√©

**Contr√¥les d'acc√®s**:
- **Azure AD Integration**: Authentification centralis√©e
- **Row Level Security (RLS)**: Isolation par tenant/client
- **Chiffrement**: At-rest (Azure Storage Encryption) et in-transit (TLS 1.2+)
- **Audit**: Logs d'audit ADX activ√©s

**Compliance**:
- GDPR: Support PII masking et data retention policies
- SOC 2, ISO 27001 compliance native Azure

## Architecture de D√©ploiement

### Configuration Multi-r√©gions

**R√©gion primaire** (ex: West Europe):
- Cluster ADX primaire
- Event Hubs namespace primaire
- Compute pour ingestion

**R√©gion secondaire** (ex: North Europe):
- Cluster ADX en standby ou lecture
- R√©plication via Follower Database
- Disaster Recovery: RPO < 1h, RTO < 4h

### R√©seau et Connectivit√©

- **Virtual Network**: Int√©gration VNet pour isolation
- **Private Endpoints**: Connexions priv√©es pour ADX
- **Service Endpoints**: Event Hubs, Storage s√©curis√©s
- **Firewall**: IP whitelisting sur cluster ADX

## Flux de Donn√©es

1. **G√©n√©ration de logs** ‚Üí Applications/Services
2. **Collection** ‚Üí Agents (Fluentd, Logstash, Azure Monitor Agent)
3. **Streaming** ‚Üí Event Hubs (buffering)
4. **Ingestion** ‚Üí ADX (compression, indexation)
5. **Transformation** ‚Üí Update policies (enrichissement)
6. **Stockage** ‚Üí Tiered storage (hot ‚Üí warm ‚Üí cold)
7. **Analyse** ‚Üí KQL queries via portails/APIs
8. **Visualisation** ‚Üí Power BI, Grafana, Azure Dashboards

## Patterns d'Usage

### Use Case 1: Monitoring Temps R√©el
- Dashboards en temps r√©el (rafra√Æchissement 30s)
- Alertes automatiques sur anomalies
- Latence: < 2 minutes end-to-end

### Use Case 2: Investigations de S√©curit√©
- Requ√™tes ad-hoc sur 90 jours de donn√©es
- Corr√©lation d'√©v√©nements complexes
- Time to insight: Secondes √† minutes

### Use Case 3: Analytics Historiques
- Tendances mensuelles/annuelles
- Capacit√© planning
- Requ√™tes sur cold storage: Minutes

## Int√©grations

### Sources de Logs
- **Azure**: Application Insights, Azure Monitor, Activity Logs
- **On-premises**: Syslog, Windows Events via agents
- **Applications**: Logs applicatifs JSON/structur√©s
- **S√©curit√©**: Firewall logs, IDS/IPS, WAF

### Consommateurs
- **Power BI**: Dashboards ex√©cutifs
- **Grafana**: Dashboards op√©rationnels
- **Azure Logic Apps**: Automatisation bas√©e sur requ√™tes
- **APIs REST**: Int√©gration applications custom
- **ADX Web UI**: Exploration interactive

## √âvolutivit√©

### Scaling Vertical
- Augmentation SKU des n≈ìuds (E8 ‚Üí E16 ‚Üí E32 ‚Üí E64)
- Impact: Plus de RAM, CPU pour requ√™tes complexes

### Scaling Horizontal
- Ajout de n≈ìuds au cluster
- Impact: Plus de d√©bit d'ingestion et parall√©lisme des requ√™tes

### Auto-scaling
- Configuration bas√©e sur:
  - CPU utilization (> 70%)
  - Ingestion queue depth
  - Query latency metrics

## Monitoring et Observabilit√©

### M√©triques cl√©s
- **Ingestion**:
  - Events ingested/sec
  - Ingestion latency
  - Failed ingestions
  
- **Query Performance**:
  - Query duration (p50, p95, p99)
  - Queries per second
  - Cache hit ratio

- **Ressources**:
  - CPU/Memory utilization
  - Disk IOPS
  - Network throughput

### Outils de Monitoring
- **Azure Monitor**: M√©triques et alertes
- **ADX Insights**: Dashboard int√©gr√©
- **Log Analytics**: Meta-monitoring des logs ADX
- **Application Insights**: Pour applications connect√©es

## Haute Disponibilit√©

### R√©silience du Cluster
- **N≈ìuds multiples**: Minimum 3 n≈ìuds pour HA
- **R√©plication**: Data repliqu√©e sur multiple n≈ìuds
- **Zone Redundancy**: Distribution sur Availability Zones

### Disaster Recovery
- **Follower Databases**: Lecture seule en r√©gion secondaire
- **Backup**: Continuous export vers Storage
- **Recovery**: Restore from Storage ou promote follower

## Optimisations

### Performance
1. **Partitioning**: Par date (colonnes datetime)
2. **Materialized Views**: Pr√©-agr√©gations pour requ√™tes fr√©quentes
3. **Cache Policy**: Optimisation du hot cache
4. **Extent Management**: Merge policy pour petits extents

### Co√ªts
1. **Tiered Storage**: Donn√©es froides en Azure Storage
2. **Reserved Capacity**: R√©servations 1-3 ans
3. **Continuous Export**: Archive vers Blob Storage
4. **Auto-pause**: Dev/Test clusters en dehors heures

## Conformit√© et Gouvernance

### Data Governance
- **Data Classification**: Tags sur tables/colonnes
- **Retention Policies**: Automatiques par table
- **Data Lineage**: Tracking via metadata

### Audit et Logging
- **Audit Logs**: Toutes op√©rations DDL/DML
- **Query Audit**: Tracking des queries utilisateurs
- **Access Logs**: Connexions et authentifications

## Roadmap et √âvolution

### Phase 1 (Mois 1-2): Foundation
- D√©ploiement cluster ADX de base
- Ingestion batch via Storage
- Requ√™tes KQL basiques

### Phase 2 (Mois 3-4): Optimisation
- Migration vers streaming Event Hubs
- Update policies pour enrichissement
- Dashboards Power BI/Grafana

### Phase 3 (Mois 5-6): Scaling
- Multi-region setup
- Optimisations performance avanc√©es
- Int√©grations additionnelles

### Phase 4 (Mois 6+): Excellence Op√©rationnelle
- Auto-scaling automation
- ML pour d√©tection anomalies
- Self-service analytics pour √©quipes

## R√©f√©rences

- [Azure Data Explorer Documentation](https://docs.microsoft.com/azure/data-explorer/)
- [KQL Quick Reference](https://docs.microsoft.com/azure/data-explorer/kql-quick-reference)
- [ADX Best Practices](https://docs.microsoft.com/azure/data-explorer/best-practices)
- [Pricing Calculator](https://azure.microsoft.com/pricing/calculator/)

## Documents Connexes

- [Solution Technique ADX](./adx-solution.md)
- [Exemples KQL](./kql-examples.md)
- [Strat√©gie d'Ingestion](./data-ingestion.md)
- [Estimation de Co√ªts](./cost-estimation.md)
- [Diagrammes d'Architecture](./diagrams/)
# Estimation Financi√®re - Solution Azure Data Explorer 5TB/Jour

## R√©sum√© Ex√©cutif

Cette estimation financi√®re d√©taille les co√ªts mensuels et annuels d'une solution Azure Data Explorer pour l'analyse de **5 TB de logs par jour**.

### Co√ªts Mensuels Estim√©s

| Composant | Co√ªt Mensuel (USD) | % du Total |
|-----------|-------------------:|----------:|
| **Azure Data Explorer Cluster** | $13,824 | 68% |
| **Event Hubs** | $3,456 | 17% |
| **Stockage (Hot + Cold)** | $2,160 | 11% |
| **Network Egress** | $500 | 2% |
| **Monitoring & Management** | $400 | 2% |
| **TOTAL** | **$20,340** | **100%** |

### Co√ªts Annuels: **~$244,080**

---

## D√©tail par Composant

### 1. Azure Data Explorer (ADX) - Cluster Principal

#### Configuration Recommand√©e

**Cluster Compute**:
- **SKU**: Standard_E16s_v5
  - vCPUs: 16 cores
  - RAM: 128 GB
  - SSD Cache: 512 GB
- **Nombre de n≈ìuds**: 8 n≈ìuds
- **R√©gion**: West Europe (exemple)

#### Calcul des Co√ªts ADX

**Prix unitaire** (West Europe, tarifs juin 2024):
- Standard_E16s_v5: ~$1.44/heure/n≈ìud

**Co√ªt mensuel**:
```
8 n≈ìuds √ó $1.44/h √ó 730h/mois = $8,409.60/mois
```

**Markup Azure**: ~20% pour gestion et overhead = **$10,091/mois**

#### Options de R√©duction des Co√ªts

**Reserved Instances (1 an)**:
- R√©duction: ~38%
- Nouveau co√ªt: **$6,256/mois** (~$75,000/an)
- √âconomie: **$3,835/mois** ($46,000/an)

**Reserved Instances (3 ans)**:
- R√©duction: ~62%
- Nouveau co√ªt: **$3,835/mois** (~$46,000/an)
- √âconomie: **$6,256/mois** ($75,000/an)

#### Dimensionnement Alternatif

| Configuration | N≈ìuds | SKU | Co√ªt/mois | Use Case |
|---------------|-------|-----|----------:|-----------|
| **Minimal** | 6 | E8s_v5 | $4,200 | Dev/Test |
| **Standard** | 8 | E16s_v5 | $10,091 | Production (baseline) |
| **Optimis√©** | 8 | E16s_v5 + RI 3ans | $3,835 | Production (optimis√©) |
| **Premium** | 10 | E16s_v5 | $12,614 | Peak loads, HA |
| **Enterprise** | 12 | E32s_v5 | $34,560 | High concurrency |

**Recommandation**: Commencer avec configuration Standard, puis optimiser avec Reserved Instances apr√®s 3-6 mois.

#### Co√ªt Stockage ADX (Hot Storage)

**Hot Storage** (90 jours de r√©tention):
- Volume brut: 5 TB/jour √ó 90 jours = 450 TB
- Apr√®s compression 10:1: 45 TB
- Prix: ~$0.08/GB/mois
- Co√ªt mensuel: 45,000 GB √ó $0.08 = **$3,600/mois**

**Hot Cache** (SSD, inclus dans compute):
- Capacit√©: 8 n≈ìuds √ó 512 GB = 4 TB
- R√©tention: 7-14 jours
- Co√ªt: **Inclus dans le co√ªt des n≈ìuds**

**Total ADX (Compute + Hot Storage)**: **$13,691/mois** (sans RI)

---

### 2. Azure Event Hubs

#### Configuration Recommand√©e

**Namespace**:
- **Tier**: Standard
- **Throughput Units (TU)**: 10 TU base, auto-inflate jusqu'√† 20 TU
- **Partitions**: 32 partitions
- **Retention**: 1 jour

#### Calcul des Co√ªts Event Hub

**Co√ªts de base**:
- Base namespace (Standard): ~$10/mois
- Throughput Units: $30/TU/mois
- Average TUs utilis√©s: ~10 TU
- Ingress events: 5 TB/jour √∑ 500 bytes/event = ~10 milliards events/jour

**Co√ªts mensuels**:
```
Base: $10/mois
Throughput: 10 TU √ó $30 = $300/mois
Ingress events: 10B events/jour √ó 30 jours = 300B events/mois
  300B events √∑ 1M = 300,000 million events
  Premier 100M: Gratuit
  200M-6000M: $0.028/million = 5,900 √ó $0.028 = $165.20
  Restant: 294,100M √ó $0.011 = $3,235.10

Total Event Hub: ~$3,710/mois
```

**Estimation simplifi√©e**: **$3,456/mois** (avec optimisations)

#### Options Alternatives

**Premium Tier**:
- Processing Units (PU): 1 PU
- Co√ªt: ~$672/PU/mois
- Avantages: VNet isolation, plus de capacit√©
- Recommand√© si: Besoin isolation r√©seau forte

**Dedicated Cluster**:
- Capacity Units (CU): 1 CU
- Co√ªt: ~$8,760/mois
- Avantages: D√©di√©, pr√©visible, pas de throttling
- Recommand√© si: > 10 TB/jour ou tr√®s strict SLA

---

### 3. Azure Blob Storage

#### Configuration pour Stockage Froid

**Cold Storage** (1-2 ans au-del√† de hot):
- Volume: 5 TB/jour √ó 365 jours = 1,825 TB/an
- Apr√®s compression 10:1: 182.5 TB/an
- Strat√©gie: D√©placer donn√©es > 90 jours vers Blob Cool Tier

**Ann√©e 1**:
- Volume moyen: 91 TB (rampe progressive)
- Prix Cool Tier: ~$0.0184/GB/mois
- Co√ªt: 91,000 GB √ó $0.0184 = **$1,674/mois**

**Ann√©e 2** (steady state):
- Volume: 182.5 TB
- Co√ªt: 182,500 GB √ó $0.0184 = **$3,358/mois**

**Co√ªt moyen Ann√©e 1-2**: **$2,516/mois**

#### Transactions et Operations

**Continuous Export** (ADX ‚Üí Blob):
- Write operations: ~100,000/jour
- Co√ªt write: $0.10/10,000 ops
- Co√ªt mensuel: 3M ops √ó $0.01 = **$30/mois**

**Read operations** (requ√™tes cold data):
- Estim√©: 10,000/jour
- Co√ªt: Marginal (~$5/mois)

#### Batch Ingestion (si utilis√© au lieu Event Hub)

**Alternative moins ch√®re pour ingestion**:
- Stockage temporaire: ~500 GB (1 jour buffer)
- Co√ªt: 500 GB √ó $0.0184 = $9.20/mois
- Lifecycle policy: Suppression automatique apr√®s 2 jours

**Total Stockage**: **$1,674/mois** (Ann√©e 1) ‚Üí **$3,358/mois** (Ann√©e 2)

---

### 4. R√©seau (Network Egress)

#### Transferts de Donn√©es

**Intra-Azure**:
- Event Hub ‚Üí ADX (m√™me r√©gion): **Gratuit**
- Blob ‚Üí ADX (m√™me r√©gion): **Gratuit**
- ADX ‚Üí Follower DB (autre r√©gion): $0.05/GB

**Internet Egress** (API queries, dashboards):
- Estim√©: 2 TB/mois (dashboards, APIs, exports)
- Prix zone 1 (Europe): $0.087/GB (premiers 10 TB)
- Co√ªt: 2,000 GB √ó $0.087 = **$174/mois**

**Power BI/Grafana Queries**:
- Queries retournent g√©n√©ralement agr√©gats (petits volumes)
- Estim√©: 500 GB/mois
- Co√ªt: 500 GB √ó $0.087 = **$43.50/mois**

**Total Network**: **$500/mois** (estimation conservative)

---

### 5. Monitoring et Management

#### Azure Monitor

**M√©triques et Logs**:
- M√©triques ADX: 100 m√©triques √ó $0.10 = $10/mois
- Log ingestion (monitoring ADX): 50 GB/mois √ó $2.76/GB = $138/mois
- Log retention: 30 jours (standard)

**Total Azure Monitor**: **$148/mois**

#### Alertes et Actions

**Alertes**:
- ~20 r√®gles d'alerte
- Co√ªt: $0.10/r√®gle/mois = $2/mois
- Evaluations: Incluses (premi√®res 1000 gratuites)

**Action Groups**:
- Email notifications: Gratuit
- Logic Apps triggers: ~$50/mois

**Total Alertes**: **$52/mois**

#### Management Overhead

**Azure Advisor, Security Center, etc.**:
- Standard tier: ~$200/mois
- Inclut: Recommendations, security scanning, compliance

**Total Monitoring & Management**: **$400/mois**

---

### 6. Services Additionnels

#### Power BI (Optionnel)

**Power BI Premium Per User**:
- ~10 utilisateurs analystes
- $20/user/mois = **$200/mois**

**Power BI Embedded** (pour dashboards publics):
- A1 capacity: $1/heure = ~$730/mois
- Recommand√© si: Dashboards pour >100 users

#### Grafana (Open Source)

**Self-hosted sur AKS**:
- 2 n≈ìuds B4ms: ~$160/mois
- Stockage: ~$40/mois
- Total: **$200/mois**

**Grafana Cloud** (Alternative):
- Pro plan: $299/mois

#### Azure Key Vault

**Stockage de secrets**:
- ~50 secrets
- Co√ªt: $0.03/10,000 ops
- Total: ~$5/mois (n√©gligeable)

#### Private Endpoints

**Connexions priv√©es**:
- ADX: $10/mois
- Event Hub: $10/mois
- Storage: $10/mois
- Total: **$30/mois**

---

## Sc√©narios de Co√ªts

### Sc√©nario 1: Production Optimis√©e (Recommand√©)

| Composant | Co√ªt Mensuel |
|-----------|-------------:|
| ADX Cluster (8 √ó E16s_v5, RI 3 ans) | $3,835 |
| ADX Hot Storage (90 jours) | $3,600 |
| Event Hubs (Standard, 10 TU) | $3,456 |
| Blob Cold Storage | $1,674 |
| Network | $500 |
| Monitoring | $400 |
| **TOTAL** | **$13,465/mois** |
| **ANNUEL** | **$161,580** |

**Avec Power BI et Grafana**: **$13,865/mois** ($166,380/an)

---

### Sc√©nario 2: Startup / Co√ªt Minimum

**Optimisations**:
- ADX: 6 n≈ìuds E8s_v5 (au lieu de 8 √ó E16s_v5)
- Event Hub remplac√© par Blob batch ingestion
- Hot storage: 30 jours (au lieu de 90)
- Pas de Reserved Instances (flexibilit√©)

| Composant | Co√ªt Mensuel |
|-----------|-------------:|
| ADX Cluster (6 √ó E8s_v5) | $3,150 |
| ADX Hot Storage (30 jours) | $1,200 |
| Blob Ingestion + Storage | $150 |
| Network | $300 |
| Monitoring | $200 |
| **TOTAL** | **$5,000/mois** |
| **ANNUEL** | **$60,000** |

**Trade-offs**:
- ‚ö†Ô∏è Latence ingestion: 5-15 minutes (vs <2 min)
- ‚ö†Ô∏è Moins de ressources pour queries complexes
- ‚ö†Ô∏è R√©tention hot r√©duite (30j vs 90j)

---

### Sc√©nario 3: Enterprise avec HA Multi-r√©gion

**Ajouts**:
- Cluster secondaire (follower): 50% du co√ªt primaire
- Geo-replication pour stockage
- Premium Event Hubs
- Multi-region networking

| Composant | Co√ªt Mensuel |
|-----------|-------------:|
| ADX Cluster Primaire (RI 3 ans) | $7,435 |
| ADX Cluster Secondaire (follower) | $3,718 |
| Event Hubs Premium | $672 |
| Blob Storage (GRS) | $3,348 |
| Network (multi-region) | $1,500 |
| Monitoring | $600 |
| **TOTAL** | **$17,273/mois** |
| **ANNUEL** | **$207,276** |

**Avantages**:
- ‚úÖ RPO < 15 minutes
- ‚úÖ RTO < 1 heure
- ‚úÖ Lecture distribu√©e (performance)
- ‚úÖ SLA 99.99%

---

## √âvolution des Co√ªts sur 3 Ans

### Projection (Sc√©nario Production Optimis√©e)

**Hypoth√®ses**:
- Croissance volume: 10% par an
- Pas d'augmentation des prix Azure (conservatif)
- Reserved Instances renouvel√©es

| Ann√©e | Volume/Jour | ADX Compute | Storage Total | Event Hub | Total Mensuel | Total Annuel |
|-------|-------------|-------------|---------------|-----------|--------------|-------------|
| **An 1** | 5 TB | $7,435 | $3,600 | $3,456 | $15,291 | $183,492 |
| **An 2** | 5.5 TB | $7,435 | $7,258 | $3,802 | $18,795 | $225,540 |
| **An 3** | 6 TB | $8,179 | $10,910 | $4,182 | $23,571 | $282,852 |

**Note**: An 1 Storage = Hot uniquement; An 2+ inclut accumulation de cold storage.

---

## Optimisations des Co√ªts

### 1. Reserved Instances (RI)

**Impact**:
- 1 an: -38% compute ‚Üí √âconomie $46,000/an
- 3 ans: -62% compute ‚Üí √âconomie $75,000/an

**Recommandation**: RI 3 ans apr√®s 6 mois de validation.

### 2. Tiered Storage Strategy

**Strat√©gie**:
```
Hot Cache (SSD): 7 jours ‚Üí Requ√™tes critiques
Hot Storage: 30 jours ‚Üí Requ√™tes fr√©quentes  
Cold Storage (Blob): 31-365 jours ‚Üí Historique
Archive: >1 an ‚Üí Compliance
```

**Impact**: R√©duction stockage de **40-60%**

### 3. Compression et Formats

**Parquet vs JSON**:
- Parquet: 50-70% plus petit
- Impact: R√©duction Event Hub throughput (moins de TUs)
- √âconomie estim√©e: **$500-800/mois**

### 4. Batch au lieu de Streaming (si acceptable)

**Remplacement Event Hub par Blob**:
- √âconomie: ~$3,456/mois
- Trade-off: Latence 5-15 min (vs <2 min)
- **Recommand√© pour**: Dev/test, logs non-critiques

### 5. Query Optimization

**Materialized Views**:
- Pr√©-agr√©gations pour dashboards fr√©quents
- R√©duction compute jusqu'√† **70%** pour ces queries

**Cache Policy Tuning**:
- Identifier queries fr√©quentes
- Ajuster hot cache (7-14 jours)
- Impact: P95 latency ‚àí50%

### 6. Cleanup & Retention Policies

**Aggressive cleanup**:
- Logs debug/trace: 30 jours seulement
- Logs info: 90 jours
- Logs error/critical: 1 an

**Impact**: R√©duction storage de **30-50%**

### 7. Auto-scaling

**Metrics-based scaling**:
- Scale down durant heures creuses
- √âconomie: **15-25%** (si usage variable)
- Exemple: 8 n≈ìuds peak, 5 n≈ìuds off-hours

---

## Comparaison avec Alternatives

### Azure Data Explorer vs Alternatives

| Solution | Co√ªt Mensuel Estim√© | Avantages | Inconv√©nients |
|----------|--------------------:|-----------|---------------|
| **ADX** | **$13,465-20,340** | Performance, KQL, int√©gration Azure | Co√ªt compute √©lev√© |
| **Elasticsearch (self-hosted AKS)** | $8,000-12,000 | Mature, flexible | Gestion complexe, HA difficile |
| **Elastic Cloud** | $15,000-25,000 | Manag√©, ecosystem riche | Co√ªt √©lev√© pour volume |
| **Splunk Cloud** | $30,000-50,000 | Tr√®s mature, features riches | Tr√®s cher (GB ingested) |
| **Datadog Logs** | $25,000-40,000 | SaaS, simple | Tr√®s cher √† scale |
| **Azure Log Analytics** | $18,000-28,000 | Int√©gr√© Azure Monitor | Moins performant queries complexes |
| **AWS OpenSearch** | $10,000-16,000 | Manag√©, scaling | Pas Azure natif |

**Conclusion**: ADX offre le **meilleur ratio performance/co√ªt** pour 5TB/jour avec Azure.

---

## ROI et Justification

### Co√ªts √âvit√©s

**Sans solution centralis√©e**:
- Dev time debugging: 100h/mois √ó $100/h = $10,000/mois
- Downtime costs: 2h/mois √ó $50,000/h = $100,000/mois (si e-commerce)
- Incidents non d√©tect√©s: Incalculable

**Avec ADX**:
- Time to insight: Minutes (vs heures/jours)
- Proactive detection: √âviter incidents
- Capacity planning: Optimiser infra

**ROI estim√©**: 3-6 mois pour entreprises moyennes/grandes

### B√©n√©fices Business

**Quantifiables**:
- ‚Üì 60% temps debugging (√©quipes ops/dev)
- ‚Üì 40% MTTR (Mean Time To Restore)
- ‚Üì 30% incidents production (d√©tection proactive)

**Non-quantifiables**:
- Meilleure compliance (audit trails)
- Insights business (analytics sur logs applicatifs)
- Confiance clients (moins de downtime)

---

## Recommandations Finales

### Phase 1: Pilot (Mois 1-3)

**Budget**: $5,000-7,000/mois
- Cluster minimal (6 n≈ìuds E8s_v5)
- Blob ingestion batch
- 30 jours hot storage
- Pas de RI (flexibilit√©)

### Phase 2: Production (Mois 4-6)

**Budget**: $15,000-18,000/mois
- Cluster production (8 n≈ìuds E16s_v5)
- Event Hubs streaming
- 90 jours hot storage
- Monitoring complet

### Phase 3: Optimisation (Mois 7-12)

**Budget**: $13,000-15,000/mois
- Reserved Instances 3 ans
- Tiered storage optimis√©
- Materialized views
- Auto-scaling

### Phase 4: Scale & HA (Ann√©e 2+)

**Budget**: $15,000-20,000/mois
- Multi-r√©gion si besoin
- Query optimizations
- ML pour anomaly detection
- Self-service analytics

---

## Checklist Budget

### Mensuel

- [ ] Azure Data Explorer compute
- [ ] ADX hot storage
- [ ] Event Hubs ou Blob Storage
- [ ] Network egress
- [ ] Azure Monitor
- [ ] Alertes et actions

### Optionnel

- [ ] Power BI licenses
- [ ] Grafana hosting
- [ ] Private endpoints
- [ ] Follower database (DR)
- [ ] Support Azure (Standard/Professional)

### Annuel

- [ ] Reserved Instances (renouvellement)
- [ ] Storage lifecycle optimization review
- [ ] Capacity planning update
- [ ] Cost optimization audit

---

## Contacts et Ressources

**Azure Pricing Calculator**:
https://azure.microsoft.com/pricing/calculator/

**ADX Pricing Details**:
https://azure.microsoft.com/pricing/details/data-explorer/

**Event Hubs Pricing**:
https://azure.microsoft.com/pricing/details/event-hubs/

**Storage Pricing**:
https://azure.microsoft.com/pricing/details/storage/blobs/

**Azure Cost Management**:
https://portal.azure.com/#blade/Microsoft_Azure_CostManagement

---

## Conclusion

Pour une solution d'analyse de **5 TB de logs par jour** avec Azure Data Explorer:

**Co√ªt Production Baseline**: **$15,000-20,000/mois** ($180,000-240,000/an)

**Co√ªt Production Optimis√©**: **$13,000-15,000/mois** ($156,000-180,000/an)

**Recommandation**: Commencer avec configuration standard, valider pendant 3-6 mois, puis optimiser avec Reserved Instances et tiered storage pour r√©duire les co√ªts de **30-40%**.

Le **ROI est positif** d√®s 3-6 mois pour la majorit√© des entreprises gr√¢ce √† la r√©duction du temps de debugging et la d√©tection proactive d'incidents.
# Strat√©gie d'Ingestion de Donn√©es

## Vue d'ensemble

L'ingestion de 5TB de logs par jour (~208 GB/heure en moyenne) n√©cessite une architecture robuste, scalable et r√©siliente. Ce document d√©taille les diff√©rentes strat√©gies d'ingestion pour Azure Data Explorer.

## Volume et Contraintes

### M√©triques Cibles
- **Volume quotidien**: 5 TB (non compress√©)
- **D√©bit moyen**: ~208 GB/heure (~58 MB/seconde)
- **D√©bit peak**: ~625 GB/heure (facteur 3x aux heures de pointe)
- **Latence souhait√©e**: < 2 minutes end-to-end
- **Format principal**: JSON structur√©
- **Compression ratio**: 10:1 (5TB ‚Üí 500GB stock√©)

### Contraintes Techniques
- **Limites ADX**: 
  - Ingestion: ~200 GB/heure/n≈ìud
  - Fichiers optimaux: 100MB - 1GB
  - Batch size: 1GB ou 1000 blobs
- **Network**: Bandwidth suffisant (10+ Gbps)
- **Event Hub**: 32+ partitions recommand√©es

## Options d'Ingestion

### Option 1: Azure Event Hubs (Streaming) - ‚≠ê RECOMMAND√â

#### Architecture
```
Applications/Services
    ‚Üì
Agents de collecte (Fluentd/Logstash/Vector)
    ‚Üì
Azure Event Hubs (32+ partitions)
    ‚Üì
ADX Data Connection (Native integration)
    ‚Üì
Azure Data Explorer Tables
```

#### Avantages
- ‚úÖ **Faible latence**: < 30 secondes √† 2 minutes
- ‚úÖ **D√©couplage**: Buffer entre producers et consumers
- ‚úÖ **R√©silience**: Retry automatique, dead-letter queue
- ‚úÖ **Scaling**: Auto-inflate jusqu'√† 40 TUs
- ‚úÖ **Simplicit√©**: Gestion automatique par ADX

#### Configuration Event Hub

**Namespace**:
```bash
az eventhubs namespace create \
  --name "loganalysis-prod-eh" \
  --resource-group "rg-loganalysis-prod" \
  --location "westeurope" \
  --sku "Standard" \
  --enable-auto-inflate true \
  --maximum-throughput-units 20 \
  --capacity 10
```

**Event Hub**:
```bash
az eventhubs eventhub create \
  --name "application-logs" \
  --namespace-name "loganalysis-prod-eh" \
  --partition-count 32 \
  --message-retention 1 \
  --cleanup-policy "Delete"
```

**Param√®tres cl√©s**:
- **Partitions**: 32 (permet 32 MB/s = ~115 GB/h)
- **Throughput Units**: 10-20 (1 TU = 1 MB/s ingress)
- **Retention**: 1 jour (suffisant pour buffer)
- **Auto-inflate**: Activ√© pour peaks

#### Calcul du dimensionnement

```
D√©bit peak: 625 GB/h = 173 MB/s
Avec compression 2:1 (avant Event Hub): ~86 MB/s
Throughput Units requis: 86 TU
Avec auto-inflate: Commencer √† 10 TU, scaler √† 20 TU

Partitions pour parall√©lisme ADX:
32 partitions √ó 1 MB/s = 32 MB/s base
Avec burst: ~100-150 MB/s
Couverture: 86 MB/s ‚úì
```

#### Data Connection ADX

```kql
.create-or-alter table ApplicationLogs ingestion eventhub data connection 'ApplicationLogsConnection'
```json
{
  "properties": {
    "eventHubResourceId": "/subscriptions/{sub-id}/resourceGroups/rg-loganalysis-prod/providers/Microsoft.EventHub/namespaces/loganalysis-prod-eh/eventhubs/application-logs",
    "consumerGroup": "adx-consumer",
    "tableName": "ApplicationLogs",
    "mappingRuleName": "ApplicationLogsMapping",
    "dataFormat": "JSON",
    "compression": "GZip",
    "eventSystemProperties": ["x-opt-enqueued-time"],
    "managedIdentityResourceId": "/subscriptions/{sub-id}/resourceGroups/rg-loganalysis-prod/providers/Microsoft.ManagedIdentity/userAssignedIdentities/adx-identity"
  }
}
```
```

#### Configuration des Agents de Collecte

**Fluentd**:
```yaml
<source>
  @type tail
  path /var/log/application/*.log
  pos_file /var/log/td-agent/application.log.pos
  tag application.logs
  format json
  time_key timestamp
  time_format %Y-%m-%dT%H:%M:%S.%LZ
</source>

<filter application.logs>
  @type record_transformer
  enable_ruby true
  <record>
    hostname "#{Socket.gethostname}"
    environment "#{ENV['ENVIRONMENT']}"
    region "#{ENV['AZURE_REGION']}"
  </record>
</filter>

<match application.logs>
  @type azure_event_hubs
  connection_string "#{ENV['EVENT_HUB_CONNECTION_STRING']}"
  hub_name "application-logs"
  
  # Batching pour efficacit√©
  <buffer>
    @type file
    path /var/log/td-agent/buffer/eventhub
    flush_mode interval
    flush_interval 10s
    chunk_limit_size 5MB
    total_limit_size 1GB
    retry_type exponential_backoff
    retry_max_interval 30s
  </buffer>
  
  # Compression
  compress gzip
</match>
```

**Vector** (Alternative moderne):
```toml
[sources.application_logs]
type = "file"
include = ["/var/log/application/*.log"]
data_dir = "/var/lib/vector"

[transforms.parse_json]
type = "remap"
inputs = ["application_logs"]
source = '''
  . = parse_json!(.message)
  .hostname = get_hostname!()
  .environment = get_env_var!("ENVIRONMENT")
'''

[sinks.azure_event_hub]
type = "azure_event_hubs"
inputs = ["parse_json"]
connection_string = "${EVENT_HUB_CONNECTION_STRING}"
hub_name = "application-logs"
encoding.codec = "json"

# Batching
batch.max_bytes = 5242880  # 5MB
batch.timeout_secs = 10

# Compression
compression = "gzip"
```

#### Monitoring Event Hub

```kql
// M√©triques Event Hub dans ADX
.show commands
| where CommandType == "DataIngestPull"
| where OriginalClientRequestId contains "eventhub"
| summarize 
    EventCount = sum(RowCount),
    TotalSizeGB = sum(ResourceUtilization.MemoryPeak) / 1024 / 1024 / 1024,
    AvgLatencySeconds = avg(Duration) / 1000.0
  by bin(StartedOn, 5m)
| render timechart
```

---

### Option 2: Azure Blob Storage (Batch) - Pour Historique

#### Architecture
```
Applications/Services
    ‚Üì
Agents de collecte
    ‚Üì
Azure Blob Storage (hourly batches)
    ‚Üì
Event Grid Notification
    ‚Üì
ADX Data Connection
    ‚Üì
Azure Data Explorer Tables
```

#### Avantages
- ‚úÖ **Co√ªt r√©duit**: Pas de Event Hub
- ‚úÖ **Simplicit√©**: Drop de fichiers
- ‚úÖ **R√©ingestion**: Facile √† rejouer
- ‚úÖ **Formats vari√©s**: JSON, Parquet, CSV, Avro

#### Inconv√©nients
- ‚ö†Ô∏è **Latence plus √©lev√©e**: 5-15 minutes
- ‚ö†Ô∏è **Moins de r√©silience**: Pas de buffer

#### Configuration Storage Account

```bash
az storage account create \
  --name "loganalyticsprodsa" \
  --resource-group "rg-loganalysis-prod" \
  --location "westeurope" \
  --sku "Standard_LRS" \
  --kind "StorageV2" \
  --access-tier "Hot" \
  --enable-hierarchical-namespace true  # Data Lake Gen2

az storage container create \
  --account-name "loganalyticsprodsa" \
  --name "application-logs" \
  --public-access off
```

#### Event Grid Configuration

```bash
# Event Grid Topic
az eventgrid topic create \
  --name "storage-events-topic" \
  --resource-group "rg-loganalysis-prod" \
  --location "westeurope"

# Event Grid Subscription
az eventgrid event-subscription create \
  --name "blob-created-subscription" \
  --source-resource-id "/subscriptions/{sub-id}/resourceGroups/rg-loganalysis-prod/providers/Microsoft.Storage/storageAccounts/loganalyticsprodsa" \
  --endpoint-type "azurefunction" \
  --endpoint "/subscriptions/{sub-id}/resourceGroups/rg-loganalysis-prod/providers/Microsoft.Web/sites/adx-ingestion-func/functions/BlobCreatedHandler" \
  --included-event-types "Microsoft.Storage.BlobCreated"
```

#### Data Connection ADX

```kql
.create-or-alter table ApplicationLogs ingestion blob data connection 'StorageConnection'
```json
{
  "properties": {
    "storageAccountResourceId": "/subscriptions/{sub-id}/resourceGroups/rg-loganalysis-prod/providers/Microsoft.Storage/storageAccounts/loganalyticsprodsa",
    "containerName": "application-logs",
    "eventGridResourceId": "/subscriptions/{sub-id}/resourceGroups/rg-loganalysis-prod/providers/Microsoft.EventGrid/topics/storage-events-topic",
    "tableName": "ApplicationLogs",
    "mappingRuleName": "ApplicationLogsMapping",
    "dataFormat": "Parquet",
    "ignoreFirstRecord": false,
    "managedIdentityResourceId": "/subscriptions/{sub-id}/resourceGroups/rg-loganalysis-prod/providers/Microsoft.ManagedIdentity/userAssignedIdentities/adx-identity"
  }
}
```
```

#### Pattern de Naming des Fichiers

```
application-logs/
  ‚îî‚îÄ‚îÄ year=2024/
      ‚îî‚îÄ‚îÄ month=06/
          ‚îî‚îÄ‚îÄ day=15/
              ‚îî‚îÄ‚îÄ hour=14/
                  ‚îú‚îÄ‚îÄ app-logs-20240615-140000-001.parquet.gz
                  ‚îú‚îÄ‚îÄ app-logs-20240615-140000-002.parquet.gz
                  ‚îî‚îÄ‚îÄ app-logs-20240615-140000-003.parquet.gz
```

**Best practices**:
- **Taille**: 100-500 MB par fichier (apr√®s compression)
- **Format**: Parquet (meilleure compression et performance)
- **Compression**: GZip ou Snappy
- **Fr√©quence**: Toutes les 5-10 minutes

#### Script de Upload

```python
from azure.storage.blob import BlobServiceClient
import gzip
import json
from datetime import datetime
import pyarrow as pa
import pyarrow.parquet as pq

class LogUploader:
    def __init__(self, connection_string, container_name):
        self.blob_service = BlobServiceClient.from_connection_string(connection_string)
        self.container_client = self.blob_service.get_container_client(container_name)
    
    def upload_logs_parquet(self, logs, partition_date):
        # Conversion en Parquet
        table = pa.Table.from_pylist(logs)
        
        # Path avec partitioning
        year = partition_date.strftime("%Y")
        month = partition_date.strftime("%m")
        day = partition_date.strftime("%d")
        hour = partition_date.strftime("%H")
        timestamp = partition_date.strftime("%Y%m%d-%H%M%S")
        
        blob_path = f"year={year}/month={month}/day={day}/hour={hour}/logs-{timestamp}.parquet.gz"
        
        # Write to buffer
        import io
        buffer = io.BytesIO()
        pq.write_table(table, buffer, compression='gzip')
        buffer.seek(0)
        
        # Upload
        blob_client = self.container_client.get_blob_client(blob_path)
        blob_client.upload_blob(buffer, overwrite=False)
        
        print(f"Uploaded {len(logs)} logs to {blob_path}")

# Usage
uploader = LogUploader(connection_string, "application-logs")
uploader.upload_logs_parquet(log_batch, datetime.now())
```

---

### Option 3: Hybrid (Event Hub + Storage)

#### Use Cases
- **Event Hub**: Logs critiques temps r√©el (erreurs, s√©curit√©)
- **Storage**: Logs bulk non-critiques (debug, trace)

#### Routage par niveau de s√©v√©rit√©

```python
def route_log(log_entry):
    level = log_entry.get('level', 'info').lower()
    
    if level in ['error', 'critical', 'warning']:
        # Route vers Event Hub pour traitement imm√©diat
        send_to_event_hub(log_entry)
    else:
        # Route vers Storage pour batch processing
        send_to_storage(log_entry)
```

#### Configuration Fluentd avec Routing

```yaml
<match application.logs>
  @type copy
  
  # Logs critiques vers Event Hub
  <store>
    @type azure_event_hubs
    connection_string "#{ENV['EVENT_HUB_CONNECTION_STRING']}"
    hub_name "critical-logs"
    <filter>
      @type grep
      <regexp>
        key level
        pattern /(error|critical|warning)/i
      </regexp>
    </filter>
  </store>
  
  # Tous les logs vers Storage (batch)
  <store>
    @type azure_storage_append_blob
    azure_storage_account "#{ENV['STORAGE_ACCOUNT']}"
    azure_storage_access_key "#{ENV['STORAGE_KEY']}"
    azure_container "application-logs"
    path "logs/%Y/%m/%d/%H/logs-#{Socket.gethostname}-%M.json"
    
    <buffer time>
      @type file
      path /var/log/td-agent/buffer/storage
      timekey 600  # 10 minutes
      timekey_wait 60
      chunk_limit_size 256MB
    </buffer>
  </store>
</match>
```

---

## Formats de Donn√©es

### JSON (Recommand√© pour d√©marrage)

**Avantages**:
- Flexible et facile √† d√©bugger
- Support natif de dynamic types dans ADX
- Lisible par humains

**Inconv√©nients**:
- Taille plus grande (~30-40% vs Parquet)
- Parsing moins performant

**Exemple**:
```json
{
  "timestamp": "2024-06-15T14:35:42.123Z",
  "level": "error",
  "logger": "com.company.OrderService",
  "message": "Failed to process order",
  "exception": "OrderProcessingException: Timeout while contacting payment service",
  "traceId": "abc123-def456-ghi789",
  "spanId": "span-001",
  "serviceName": "OrderService",
  "environment": "production",
  "properties": {
    "orderId": "ORD-123456",
    "userId": "user-789",
    "amount": 99.99,
    "retryCount": 3
  }
}
```

### Parquet (Recommand√© pour production)

**Avantages**:
- Compression excellente (50-70% vs JSON)
- Lecture columnaire tr√®s rapide
- Sch√©ma fort et typ√©

**Inconv√©nients**:
- N√©cessite conversion c√¥t√© agent
- Moins flexible pour sch√©mas changeants

**Configuration**:
```python
import pyarrow as pa
import pyarrow.parquet as pq

# D√©finition du sch√©ma
schema = pa.schema([
    ('timestamp', pa.timestamp('ms')),
    ('level', pa.string()),
    ('logger', pa.string()),
    ('message', pa.string()),
    ('exception', pa.string()),
    ('traceId', pa.string()),
    ('serviceName', pa.string()),
    ('properties', pa.string())  # JSON stringifi√©
])

# √âcriture
pq.write_table(
    table,
    'logs.parquet',
    compression='snappy',
    use_dictionary=True
)
```

### CSV (Pour simplicit√©)

**Use case**: Logs simples, outils legacy

**Format**:
```csv
timestamp,level,serviceName,message
2024-06-15T14:35:42Z,error,OrderService,"Failed to process order"
```

---

## Transformation et Enrichissement

### Update Policy pour Enrichissement

```kql
// Fonction d'enrichissement
.create-or-alter function EnrichLogs() {
    ApplicationLogs
    | extend 
        // Parsing enrichi
        Severity = case(
            Level == "critical", 5,
            Level == "error", 4,
            Level == "warning", 3,
            Level == "info", 2,
            1
        ),
        // Extraction de m√©tadonn√©es
        ErrorCode = extract(@"errorCode=(\d+)", 1, Message),
        IPAddress = extract(@"ip=([0-9.]+)", 1, Message),
        // G√©olocalisation
        GeoInfo = geo_info_from_ip_address(extract(@"ip=([0-9.]+)", 1, Message)),
        // Cat√©gorisation
        ServiceCategory = extract(@"^([^-]+)", 1, ServiceName),
        // Date parts pour partitioning
        Year = getyear(Timestamp),
        Month = getmonth(Timestamp),
        Day = dayofmonth(Timestamp),
        Hour = hourofday(Timestamp)
    | extend
        Country = tostring(GeoInfo.country),
        City = tostring(GeoInfo.city)
    | project-away GeoInfo
}

// Table enrichie
.create table EnrichedApplicationLogs (
    Timestamp: datetime,
    Level: string,
    Severity: int,
    ServiceName: string,
    ServiceCategory: string,
    Message: string,
    ErrorCode: string,
    IPAddress: string,
    Country: string,
    City: string,
    TraceId: string,
    Year: int,
    Month: int,
    Day: int,
    Hour: int
)

// Update policy
.alter table EnrichedApplicationLogs policy update 
@'[{
    "Source": "ApplicationLogs",
    "Query": "EnrichLogs()",
    "IsEnabled": true,
    "IsTransactional": true
}]'
```

---

## Monitoring et Troubleshooting

### Dashboard d'Ingestion

```kql
// Vue d'ensemble de l'ingestion
.show commands
| where CommandType in ("DataIngestPull", "DataIngestPush")
| where StartedOn > ago(1h)
| summarize 
    IngestedRows = sum(RowCount),
    IngestedGB = sum(ResourceUtilization.MemoryPeak) / 1024 / 1024 / 1024,
    AvgLatencySeconds = avg(Duration) / 1000.0,
    P95LatencySeconds = percentile(Duration, 95) / 1000.0,
    FailedCount = countif(State == "Failed")
  by bin(StartedOn, 5m)
| render timechart
```

### D√©tection d'√âchecs

```kql
// √âchecs d'ingestion r√©cents
.show ingestion failures
| where FailedOn > ago(1h)
| project 
    FailedOn,
    Database,
    Table,
    OperationId,
    ErrorCode,
    FailureStatus,
    Details
| order by FailedOn desc
```

### Alertes Recommand√©es

**Azure Monitor Alerts**:

1. **Ingestion Rate Drop**
```kql
// Alert si ingestion < 50% de la moyenne
let baseline = ApplicationLogs
    | where ingestion_time() > ago(7d)
    | summarize AvgRowsPerMinute = count() / (7 * 24 * 60);
ApplicationLogs
| where ingestion_time() > ago(5m)
| summarize CurrentRowsPerMinute = count() / 5
| extend Baseline = toscalar(baseline)
| where CurrentRowsPerMinute < (Baseline * 0.5)
```

2. **Ingestion Latency High**
```kql
// Alert si latence > 5 minutes
ApplicationLogs
| where ingestion_time() > ago(10m)
| extend IngestionLatency = ingestion_time() - Timestamp
| summarize P95Latency = percentile(IngestionLatency, 95)
| where P95Latency > 5m
```

3. **Failed Ingestions**
```kql
// Alert si √©checs > 1% du volume
.show ingestion failures
| where FailedOn > ago(5m)
| summarize FailureCount = count()
| extend Threshold = 100  // Ajuster selon volume
| where FailureCount > Threshold
```

---

## Best Practices

### Sizing et Performance

1. **Taille des fichiers**: 100MB - 1GB (optimal)
2. **Batch frequency**: 5-10 minutes
3. **Compression**: Toujours activer (GZip ou Snappy)
4. **Partitions Event Hub**: Au moins 1 partition par 1 MB/s

### R√©silience

1. **Retry Logic**: Exponentiel backoff
2. **Dead Letter Queue**: Pour messages non ing√©rables
3. **Monitoring continu**: Alertes sur √©checs/latence
4. **Backfill capability**: Capacit√© de r√©ing√©rer depuis Storage

### S√©curit√©

1. **Managed Identities**: Pas de secrets dans config
2. **Private Endpoints**: Connexions priv√©es
3. **Encryption**: At rest et in transit
4. **Audit Logging**: Tracer toutes op√©rations d'ingestion

### Co√ªts

1. **Compression**: R√©duire network et storage costs
2. **Batch vs Streaming**: Storage moins cher que Event Hub
3. **Reserved Capacity**: Pour Event Hub et ADX
4. **Lifecycle policies**: Archiver logs anciens

---

## Checklist de D√©ploiement

### Phase 1: Setup Infrastructure
- [ ] Cr√©er cluster ADX
- [ ] Cr√©er Event Hub / Storage Account
- [ ] Configurer Event Grid (si Storage)
- [ ] Setup Managed Identities
- [ ] Configurer Private Endpoints

### Phase 2: Configuration ADX
- [ ] Cr√©er Database et Tables
- [ ] D√©finir Ingestion Mappings
- [ ] Configurer Data Connections
- [ ] Setup Update Policies
- [ ] Configurer Retention Policies

### Phase 3: Agents et Collection
- [ ] D√©ployer agents de collecte
- [ ] Configurer routing et buffering
- [ ] Tester ingestion end-to-end
- [ ] Valider formats et mappings

### Phase 4: Monitoring
- [ ] Configurer dashboards d'ingestion
- [ ] Setup alertes critiques
- [ ] Documenter runbooks
- [ ] Tester proc√©dures d'incident

### Phase 5: Optimization
- [ ] Tuner batch sizes
- [ ] Optimiser compression
- [ ] Ajuster capacit√©s
- [ ] R√©viser co√ªts

---

## Ressources

- [ADX Data Ingestion Overview](https://docs.microsoft.com/azure/data-explorer/ingest-data-overview)
- [Event Hub Best Practices](https://docs.microsoft.com/azure/event-hubs/event-hubs-messaging-exceptions)
- [Fluentd Documentation](https://docs.fluentd.org/)
- [Vector Documentation](https://vector.dev/docs/)
# Exemples KQL pour Analyse de Logs

## Introduction √† KQL (Kusto Query Language)

KQL est un langage de requ√™te optimis√© pour l'analyse de grands volumes de donn√©es, particuli√®rement efficace pour les logs et t√©l√©m√©tries. Ce document pr√©sente des exemples pratiques pour l'analyse quotidienne de logs.

## Structure de Base d'une Requ√™te KQL

```kql
TableName
| where Condition
| extend NewColumn = Expression
| summarize Aggregation by GroupBy
| order by Column
| take N
```

## Exemples par Cas d'Usage

### 1. Analyses de Base

#### Compter les logs par niveau de s√©v√©rit√©
```kql
ApplicationLogs
| where Timestamp > ago(24h)
| summarize Count = count() by Level
| order by Count desc
| render piechart
```

#### Top 10 services les plus verbeux
```kql
ApplicationLogs
| where Timestamp > ago(1h)
| summarize LogCount = count() by ServiceName
| top 10 by LogCount desc
```

#### Logs d'erreur avec contexte
```kql
ApplicationLogs
| where Level in ("Error", "Critical")
| where Timestamp > ago(1h)
| project Timestamp, ServiceName, Message, Exception, TraceId
| order by Timestamp desc
| take 100
```

### 2. Analyse Temporelle

#### Distribution horaire des logs
```kql
ApplicationLogs
| where Timestamp > ago(7d)
| summarize Count = count() by bin(Timestamp, 1h), Level
| render timechart
```

#### Comparaison jour vs jour
```kql
ApplicationLogs
| where Timestamp > ago(48h)
| extend DayCategory = iff(Timestamp > ago(24h), "Today", "Yesterday")
| summarize Count = count() by bin(Timestamp, 1h), DayCategory
| render timechart
```

#### Pattern hebdomadaire
```kql
ApplicationLogs
| where Timestamp > ago(30d)
| extend DayOfWeek = dayofweek(Timestamp)
| extend Hour = hourofday(Timestamp)
| summarize AvgLogs = avg(todouble(1)) by DayOfWeek, Hour
| render heatmap
```

### 3. Performance et Latence

#### Analyse de latence par endpoint
```kql
ApplicationLogs
| where ServiceName == "ApiGateway"
| where Timestamp > ago(1h)
| extend Endpoint = extract(@"endpoint=([^ ]+)", 1, Message)
| summarize 
    RequestCount = count(),
    P50 = percentile(DurationMs, 50),
    P95 = percentile(DurationMs, 95),
    P99 = percentile(DurationMs, 99),
    Max = max(DurationMs)
  by Endpoint
| where RequestCount > 100
| order by P95 desc
```

#### Requ√™tes lentes (SLO > 3 secondes)
```kql
ApplicationLogs
| where DurationMs > 3000
| where Timestamp > ago(24h)
| extend Endpoint = extract(@"path=([^ ]+)", 1, RequestPath)
| summarize 
    SlowRequests = count(),
    AvgDuration = avg(DurationMs),
    MaxDuration = max(DurationMs)
  by Endpoint, ServiceName
| order by SlowRequests desc
```

#### Time series de latence avec d√©tection d'anomalies
```kql
ApplicationLogs
| where ServiceName == "PaymentService"
| where Timestamp > ago(7d)
| summarize AvgDuration = avg(DurationMs) by bin(Timestamp, 5m)
| extend (anomalies, score, baseline) = series_decompose_anomalies(AvgDuration, 1.5)
| render anomalychart with (anomalycolumns=anomalies)
```

### 4. Analyse d'Erreurs

#### Top erreurs par fr√©quence
```kql
ApplicationLogs
| where Level == "Error"
| where Timestamp > ago(24h)
| extend ErrorType = extract(@"Exception: ([^:]+)", 1, Exception)
| summarize 
    ErrorCount = count(),
    AffectedUsers = dcount(UserId),
    AffectedServices = dcount(ServiceName),
    FirstOccurrence = min(Timestamp),
    LastOccurrence = max(Timestamp),
    SampleMessage = any(Message)
  by ErrorType
| order by ErrorCount desc
| take 20
```

#### Cascade d'erreurs (erreurs li√©es par TraceId)
```kql
let ErrorTraces = ApplicationLogs
    | where Level == "Error" and Timestamp > ago(1h)
    | where ServiceName == "OrderService"
    | distinct TraceId;
ApplicationLogs
| where TraceId in (ErrorTraces)
| order by TraceId, Timestamp asc
| project Timestamp, TraceId, ServiceName, Level, Message, DurationMs
```

#### Taux d'erreur par service
```kql
ApplicationLogs
| where Timestamp > ago(24h)
| summarize 
    TotalRequests = count(),
    ErrorCount = countif(Level in ("Error", "Critical")),
    ErrorRate = round(countif(Level in ("Error", "Critical")) * 100.0 / count(), 2)
  by ServiceName, bin(Timestamp, 1h)
| where TotalRequests > 100
| order by ErrorRate desc
| render timechart
```

### 5. S√©curit√© et Audit

#### Tentatives de connexion √©chou√©es
```kql
ApplicationLogs
| where Logger contains "Auth"
| where Message has_any ("login failed", "authentication failed")
| where Timestamp > ago(1h)
| extend IPAddress = extract(@"ip=([0-9.]+)", 1, Message)
| summarize 
    FailedAttempts = count(),
    UniqueUsers = dcount(UserId),
    FirstAttempt = min(Timestamp),
    LastAttempt = max(Timestamp)
  by IPAddress
| where FailedAttempts > 5
| order by FailedAttempts desc
```

#### D√©tection d'attaques par force brute
```kql
ApplicationLogs
| where Timestamp > ago(5m)
| where ResponseCode in (401, 403)
| extend IPAddress = extract(@"ip=([0-9.]+)", 1, Message)
| summarize 
    Attempts = count(),
    TargetedAccounts = make_set(UserId, 10)
  by IPAddress, bin(Timestamp, 1m)
| where Attempts > 10
| project Timestamp, IPAddress, Attempts, TargetedAccounts
```

#### Acc√®s √† ressources sensibles
```kql
ApplicationLogs
| where Timestamp > ago(7d)
| where RequestPath has_any ("/admin", "/api/sensitive", "/internal")
| summarize 
    AccessCount = count(),
    UniqueUsers = dcount(UserId),
    SuccessfulAccess = countif(ResponseCode < 400),
    BlockedAccess = countif(ResponseCode >= 400)
  by UserId, RequestPath
| where AccessCount > 0
| order by AccessCount desc
```

### 6. Analyse Multi-Service (Distributed Tracing)

#### Vue compl√®te d'une transaction
```kql
let traceId = "abc123-def456-ghi789";
ApplicationLogs
| where TraceId == traceId
| order by Timestamp asc
| project 
    Timestamp,
    ServiceName,
    Level,
    Message,
    DurationMs,
    ResponseCode,
    Step = row_number()
| extend TotalDuration = toscalar(
    ApplicationLogs 
    | where TraceId == traceId 
    | summarize max(Timestamp) - min(Timestamp)
  ) / 1ms
```

#### Services les plus lents dans la cha√Æne
```kql
ApplicationLogs
| where Timestamp > ago(1h)
| where isnotempty(TraceId)
| summarize ServiceDuration = sum(DurationMs) by TraceId, ServiceName
| summarize 
    AvgDuration = avg(ServiceDuration),
    P95Duration = percentile(ServiceDuration, 95),
    CallCount = count()
  by ServiceName
| order by P95Duration desc
```

#### Tra√ßage des d√©pendances entre services
```kql
ApplicationLogs
| where Timestamp > ago(1h)
| where isnotempty(TraceId)
| summarize by TraceId, ServiceName
| join kind=inner (
    ApplicationLogs
    | where Timestamp > ago(1h)
    | where isnotempty(TraceId)
    | summarize by TraceId, ServiceName
  ) on TraceId
| where ServiceName != ServiceName1
| summarize Count = count() by Caller = ServiceName, Callee = ServiceName1
| where Count > 10
| render force_directed_graph 
```

### 7. Analyse Business

#### Utilisateurs les plus actifs
```kql
ApplicationLogs
| where Timestamp > ago(24h)
| where isnotempty(UserId)
| summarize 
    Actions = count(),
    UniqueEndpoints = dcount(RequestPath),
    TotalDataTransferred = sum(BytesSent + BytesReceived),
    AvgResponseTime = avg(DurationMs),
    ErrorCount = countif(ResponseCode >= 400)
  by UserId
| order by Actions desc
| take 50
```

#### Analyse g√©ographique du trafic
```kql
ApplicationLogs
| where Timestamp > ago(7d)
| extend IPAddress = extract(@"ip=([0-9.]+)", 1, Message)
| extend GeoInfo = geo_info_from_ip_address(IPAddress)
| extend Country = tostring(GeoInfo.country), City = tostring(GeoInfo.city)
| where isnotempty(Country)
| summarize 
    Requests = count(),
    UniqueUsers = dcount(UserId),
    AvgLatency = avg(DurationMs)
  by Country, City
| order by Requests desc
| take 20
```

#### Funnel d'utilisation
```kql
let StartEvent = "page_view:home";
let Step1 = "page_view:product";
let Step2 = "action:add_to_cart";
let Step3 = "action:checkout";
let users_started = ApplicationLogs
    | where Timestamp > ago(7d)
    | where Message has StartEvent
    | distinct UserId;
let users_step1 = ApplicationLogs
    | where Timestamp > ago(7d)
    | where Message has Step1
    | distinct UserId;
let users_step2 = ApplicationLogs
    | where Timestamp > ago(7d)
    | where Message has Step2
    | distinct UserId;
let users_step3 = ApplicationLogs
    | where Timestamp > ago(7d)
    | where Message has Step3
    | distinct UserId;
print 
    Started = toscalar(users_started | count),
    ViewedProduct = toscalar(users_step1 | count),
    AddedToCart = toscalar(users_step2 | count),
    Checkout = toscalar(users_step3 | count)
```

### 8. Monitoring et Alerting

#### SLA monitoring (availability)
```kql
ApplicationLogs
| where Timestamp > ago(30d)
| where ServiceName == "ApiGateway"
| summarize 
    TotalRequests = count(),
    SuccessfulRequests = countif(ResponseCode < 500),
    Availability = round(countif(ResponseCode < 500) * 100.0 / count(), 3)
  by bin(Timestamp, 1d)
| extend SLAMet = Availability >= 99.9
| project Timestamp, Availability, SLAMet
```

#### D√©tection de pics anormaux
```kql
ApplicationLogs
| where Timestamp > ago(30d)
| summarize RequestCount = count() by bin(Timestamp, 5m)
| extend 
    Baseline = series_stats_dynamic(RequestCount).avg,
    StdDev = series_stats_dynamic(RequestCount).stdev
| extend Threshold = Baseline + (3 * StdDev)
| where RequestCount > Threshold
| project Timestamp, RequestCount, Baseline, Threshold
```

#### Health check des services
```kql
ApplicationLogs
| where Timestamp > ago(5m)
| summarize LastSeen = max(Timestamp) by ServiceName
| extend 
    Status = case(
        LastSeen > ago(2m), "Healthy",
        LastSeen > ago(5m), "Warning",
        "Critical"
    ),
    MinutesSinceLastLog = datetime_diff('minute', now(), LastSeen)
| project ServiceName, Status, MinutesSinceLastLog, LastSeen
| order by Status desc, MinutesSinceLastLog desc
```

### 9. Optimisation des Co√ªts

#### Top services par volume de logs
```kql
ApplicationLogs
| where Timestamp > ago(30d)
| summarize 
    LogCount = count(),
    EstimatedSizeGB = (count() * 500.0) / 1024 / 1024 / 1024 // Assuming ~500 bytes/log
  by ServiceName
| order by EstimatedSizeGB desc
| extend CumulativePercentage = round(100.0 * row_cumsum(EstimatedSizeGB) / toscalar(summarize sum(EstimatedSizeGB)), 2)
```

#### Logs de faible valeur (candidats pour r√©tention r√©duite)
```kql
ApplicationLogs
| where Level == "Debug" or Level == "Trace"
| where Timestamp > ago(7d)
| summarize 
    Count = count(),
    SizeEstimateGB = (count() * 500.0) / 1024 / 1024 / 1024
  by ServiceName, Level
| order by SizeEstimateGB desc
```

### 10. Requ√™tes Avanc√©es

#### Analyse de patterns avec regex
```kql
ApplicationLogs
| where Timestamp > ago(24h)
| extend 
    OrderId = extract(@"orderId=([A-Z0-9-]+)", 1, Message),
    Amount = todouble(extract(@"amount=(\d+\.?\d*)", 1, Message))
| where isnotempty(OrderId)
| summarize 
    TotalAmount = sum(Amount),
    OrderCount = dcount(OrderId)
  by ServiceName
```

#### Join avec table de r√©f√©rence
```kql
// Table de r√©f√©rence des services
let ServiceMetadata = datatable(ServiceName:string, Team:string, Tier:string)
[
    "AuthService", "Platform", "Critical",
    "PaymentService", "Finance", "Critical",
    "NotificationService", "Communication", "Standard"
];
ApplicationLogs
| where Timestamp > ago(1h)
| summarize ErrorCount = countif(Level == "Error") by ServiceName
| join kind=leftouter ServiceMetadata on ServiceName
| where Tier == "Critical"
| order by ErrorCount desc
```

#### Pivot dynamique
```kql
ApplicationLogs
| where Timestamp > ago(24h)
| summarize Count = count() by Level, ServiceName
| evaluate pivot(Level, sum(Count))
```

#### Analyse de s√©ries temporelles avec pr√©diction
```kql
ApplicationLogs
| where Timestamp > ago(30d)
| where ServiceName == "ApiGateway"
| summarize RequestCount = count() by bin(Timestamp, 1h)
| extend (predictions, pred_score) = series_decompose_forecast(RequestCount, 24) // Pr√©dire 24h
| render timechart
```

## Fonctions Personnalis√©es

### Fonction pour standardiser les logs
```kql
.create-or-alter function ParseApplicationLog(logLevel:string) {
    ApplicationLogs
    | where Level == logLevel
    | extend 
        NormalizedTimestamp = bin(Timestamp, 1m),
        ErrorCategory = case(
            Exception contains "Timeout", "Timeout",
            Exception contains "Connection", "Connection",
            Exception contains "Authentication", "Auth",
            "Other"
        )
    | project 
        NormalizedTimestamp,
        ServiceName,
        ErrorCategory,
        Message,
        TraceId
}

// Utilisation
ParseApplicationLog("Error")
| where NormalizedTimestamp > ago(1h)
| summarize count() by ErrorCategory
```

### Fonction pour calcul de SLI
```kql
.create-or-alter function CalculateSLI(serviceName:string, windowSize:timespan) {
    ApplicationLogs
    | where ServiceName == serviceName
    | where Timestamp > ago(windowSize)
    | summarize 
        TotalRequests = count(),
        GoodRequests = countif(ResponseCode < 500 and DurationMs < 1000),
        ErrorRequests = countif(ResponseCode >= 500),
        SlowRequests = countif(DurationMs >= 1000)
    | extend 
        SLI = round(todouble(GoodRequests) * 100.0 / TotalRequests, 2),
        ErrorRate = round(todouble(ErrorRequests) * 100.0 / TotalRequests, 2),
        SlowRate = round(todouble(SlowRequests) * 100.0 / TotalRequests, 2)
    | project SLI, ErrorRate, SlowRate, TotalRequests
}

// Utilisation
CalculateSLI("PaymentService", 1h)
```

## Best Practices KQL

### Performance
1. **Filtrer t√¥t**: Toujours utiliser `where` avant `summarize` ou `join`
2. **Limiter les colonnes**: Utiliser `project` pour r√©duire les donn√©es
3. **Utiliser le cache**: Requ√™tes sur hot cache (< 14 jours par d√©faut)
4. **√âviter les scans complets**: Toujours sp√©cifier une plage temporelle

### Lisibilit√©
1. **Indentation**: Une op√©ration par ligne
2. **Variables**: Utiliser `let` pour requ√™tes complexes
3. **Commentaires**: Documenter la logique m√©tier
4. **Naming**: Noms de colonnes explicites

### Exemple de requ√™te bien structur√©e
```kql
// Analyse des erreurs critiques avec impact business
// Author: Platform Team | Date: 2024-06-15
let timeRange = 24h;
let errorThreshold = 100;
let criticalServices = dynamic(["PaymentService", "AuthService", "OrderService"]);
//
ApplicationLogs
| where Timestamp > ago(timeRange)                    // Filtrage temporel
| where Level in ("Error", "Critical")                // Filtrage par s√©v√©rit√©
| where ServiceName in (criticalServices)             // Services critiques uniquement
| extend ErrorCategory = extract(@"^(\w+)Exception", 1, Exception)
| summarize 
    ErrorCount = count(),
    AffectedUsers = dcount(UserId),
    UniqueErrors = dcount(ErrorCategory),
    SampleMessages = make_set(Message, 3)
  by ServiceName, ErrorCategory
| where ErrorCount > errorThreshold                   // Seuil significatif
| order by ErrorCount desc
| project 
    ServiceName,
    ErrorCategory,
    ErrorCount,
    AffectedUsers,
    SampleMessages
```

## Ressources Compl√©mentaires

- [KQL Reference officielle](https://docs.microsoft.com/azure/data-explorer/kusto/query/)
- [KQL Cheat Sheet](https://github.com/marcusbakker/KQL)
- [Best Practices KQL](https://docs.microsoft.com/azure/data-explorer/kusto/query/best-practices)
- [Tutoriels interactifs](https://dataexplorer.azure.com/clusters/help/databases/Samples)

## Playground pour Pratique

Microsoft propose un cluster de d√©monstration avec donn√©es samples:
- URL: https://dataexplorer.azure.com/
- Cluster: help
- Database: Samples
- Tables: StormEvents, ContosoSales, etc.

Testez vos requ√™tes avant de les d√©ployer en production!
# Executive Summary - Solution d'Analyse de Logs 5TB/Jour

## üéØ Objectif

Analyser **5 TB de logs par jour** (~1.8 PB/an) avec des requ√™tes sub-secondes, latence d'ingestion < 2 minutes, et co√ªts optimis√©s.

## ‚úÖ Solution Recommand√©e: Azure Data Explorer (ADX)

### Pourquoi ADX?

| Crit√®re | ADX | Alternatives |
|---------|-----|--------------|
| **Performance Queries** | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê Sub-seconde | ‚≠ê‚≠ê‚≠ê Secondes |
| **Latence Ingestion** | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê < 2 min | ‚≠ê‚≠ê‚≠ê 5-15 min |
| **Compression** | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê 10:1 | ‚≠ê‚≠ê‚≠ê 5:1 |
| **Co√ªt** | ‚≠ê‚≠ê‚≠ê‚≠ê Optimal | ‚≠ê‚≠ê 2-3x plus cher |
| **Scalabilit√©** | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê Quasi-illimit√©e | ‚≠ê‚≠ê‚≠ê Complexe |
| **Facilit√©** | ‚≠ê‚≠ê‚≠ê‚≠ê KQL simple | ‚≠ê‚≠ê‚≠ê Varies |

## üìä Architecture en 5 Minutes

```
Applications/Services (5TB/jour)
         ‚Üì
   Agents Collecte (Fluentd/Vector)
         ‚Üì
   Event Hubs (32 partitions)
         ‚Üì
   Azure Data Explorer (8 n≈ìuds)
         ‚îú‚Üí Hot Cache SSD (7 jours)
         ‚îú‚Üí Hot Storage (90 jours)
         ‚îî‚Üí Cold Storage (1-2 ans)
         ‚Üì
   Dashboards (Power BI/Grafana/KQL)
```

## üí∞ Co√ªts Mensuels (R√©sum√©)

| Sc√©nario | Co√ªt/Mois | Co√ªt/An | Use Case |
|----------|----------:|--------:|----------|
| **Minimal (Dev/Test)** | $5,000 | $60,000 | POC, d√©veloppement |
| **Production Standard** | $15,291 | $183,492 | Production baseline |
| **Optimis√© (RI 3 ans)** | $13,465 | $161,580 | ‚≠ê **RECOMMAND√â** |
| **Enterprise HA** | $17,273 | $207,276 | Multi-r√©gion, SLA 99.99% |

### D√©tail Co√ªt Production Optimis√©e ($13,465/mois)

```
ADX Compute (RI 3 ans):  $3,835  (28%)
ADX Hot Storage:         $3,600  (27%)
Event Hubs:              $3,456  (26%)
Blob Cold Storage:       $1,674  (12%)
Network:                   $500  (4%)
Monitoring:                $400  (3%)
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
TOTAL:                  $13,465
```

## üèóÔ∏è Sp√©cifications Techniques

### Cluster ADX

| Composant | Sp√©cification |
|-----------|---------------|
| **N≈ìuds** | 8 √ó Standard_E16s_v5 |
| **vCPUs** | 128 cores total |
| **RAM** | 1 TB total |
| **Hot Cache SSD** | 4 TB (7-14 jours) |
| **Capacit√© Ingestion** | 1,600 GB/h (marge 3x) |
| **Availability** | 3 Availability Zones |

### Stockage

| Tier | R√©tention | Volume | Latence Query |
|------|-----------|--------|---------------|
| **Hot Cache** | 7-14 jours | 350-700 GB | 100-500 ms |
| **Hot Storage** | 90 jours | 3-4.5 TB | 500ms-2s |
| **Cold Storage** | 1-2 ans | 18-36 TB | 2-5s |

### Ingestion

| M√©thode | Latence | D√©bit | Co√ªt/Mois |
|---------|---------|-------|----------:|
| **Event Hubs** (‚≠ê Recommand√©) | < 2 min | 208 GB/h | $3,456 |
| **Blob Storage** | 5-15 min | Illimit√© | $150 |
| **Hybrid** | Variable | Mix | $1,800 |

## üìà Performance Garanties

| M√©trique | Valeur |
|----------|--------|
| **Query Latency (hot cache)** | < 500 ms |
| **Query Latency (hot storage)** | < 2 secondes |
| **Ingestion Latency** | < 2 minutes |
| **Compression Ratio** | 10:1 (5TB ‚Üí 500GB) |
| **Concurrent Queries** | 100+ |
| **SLA Availability** | 99.9% (99.99% multi-r√©gion) |

## üîë Fonctionnalit√©s Cl√©s

### Ingestion
- ‚úÖ Streaming temps r√©el (Event Hubs)
- ‚úÖ Batch processing (Blob Storage)
- ‚úÖ Formats multiples (JSON, Parquet, CSV, Avro)
- ‚úÖ Compression automatique (10:1)
- ‚úÖ Transformation √† l'ingestion (Update Policies)

### Querying (KQL)
- ‚úÖ Langage SQL-like puissant et intuitif
- ‚úÖ Time series analysis natives
- ‚úÖ Anomaly detection int√©gr√©e
- ‚úÖ Joins multi-tables
- ‚úÖ Agr√©gations complexes
- ‚úÖ Visualisations int√©gr√©es

### S√©curit√©
- ‚úÖ Azure AD authentication
- ‚úÖ Row Level Security (RLS)
- ‚úÖ Chiffrement at-rest & in-transit
- ‚úÖ VNet integration & Private Endpoints
- ‚úÖ Audit logs complets
- ‚úÖ GDPR compliant (data purge)

### Op√©rations
- ‚úÖ Auto-scaling (vertical + horizontal)
- ‚úÖ Monitoring int√©gr√© (Azure Monitor)
- ‚úÖ Alertes configurables
- ‚úÖ Disaster Recovery (follower databases)
- ‚úÖ Continuous backup
- ‚úÖ Multi-tenant isolation

## üöÄ Quick Start (3 √âtapes)

### 1. Cr√©er le Cluster ADX (15 min)
```bash
az kusto cluster create \
  --cluster-name "loganalysis-prod-adx" \
  --resource-group "rg-loganalysis-prod" \
  --location "westeurope" \
  --sku Standard_E16s_v5 \
  --capacity 8 \
  --enable-streaming-ingest true \
  --zones "1,2,3"
```

### 2. Configurer Ingestion (10 min)
```bash
# Event Hub
az eventhubs eventhub create \
  --name "application-logs" \
  --namespace-name "loganalysis-prod-eh" \
  --partition-count 32
```

### 3. Cr√©er Table et Ingestion (5 min)
```kql
.create table ApplicationLogs (
    Timestamp: datetime,
    Level: string,
    Message: string,
    ServiceName: string,
    [...]
)

.create data connection EventHubConnection [...]
```

**Total Time to Value: ~30 minutes** ‚ö°

## üìä Exemples de Requ√™tes KQL

### Top Erreurs
```kql
ApplicationLogs
| where Level == "Error" and Timestamp > ago(24h)
| summarize Count = count() by ErrorType = extract(@"Exception: ([^:]+)", 1, Exception)
| top 10 by Count desc
```

### Performance P95
```kql
ApplicationLogs
| where Timestamp > ago(1h)
| summarize P95 = percentile(DurationMs, 95) by ServiceName
| order by P95 desc
```

### D√©tection Anomalies
```kql
ApplicationLogs
| make-series ErrorRate = countif(Level == "Error") * 100.0 / count()
    default=0 on Timestamp step 5m
| extend (anomalies, score) = series_decompose_anomalies(ErrorRate, 1.5)
| where anomalies > 0
```

## üéØ ROI et B√©n√©fices

### Co√ªts √âvit√©s

| Cat√©gorie | Sans ADX | Avec ADX | √âconomie |
|-----------|----------|----------|----------|
| **Temps debugging** | 100h/mois | 40h/mois | 60h √ó $100 = **$6,000/mois** |
| **MTTR (incidents)** | 4 heures | 1.5 heures | 62% r√©duction |
| **Incidents √©vit√©s** | - | 30% r√©duction | **$30,000+/mois** |

### ROI: **Positif en 3-6 mois** üìà

### B√©n√©fices Business

**Quantifiables**:
- ‚¨áÔ∏è 60% temps debugging
- ‚¨áÔ∏è 40% MTTR (Mean Time To Restore)
- ‚¨áÔ∏è 30% incidents production
- ‚¨ÜÔ∏è 90% query performance vs alternatives

**Qualitatifs**:
- Meilleure satisfaction clients (moins de downtime)
- Insights business (analytics sur comportement users)
- Compliance am√©lior√©e (audit trails complets)
- Confiance √©quipes (visibilit√© totale)

## üìÖ Roadmap de D√©ploiement

### Mois 1-2: Foundation
- ‚úÖ Cluster ADX minimal (6 n≈ìuds)
- ‚úÖ Ingestion batch via Blob
- ‚úÖ Tables et schemas de base
- ‚úÖ KQL queries basiques
- **Budget**: $5,000-7,000/mois

### Mois 3-4: Production
- ‚úÖ Cluster production (8 n≈ìuds)
- ‚úÖ Event Hubs streaming
- ‚úÖ Update policies
- ‚úÖ Dashboards Power BI/Grafana
- **Budget**: $15,000-18,000/mois

### Mois 5-6: Optimisation
- ‚úÖ Reserved Instances (RI 3 ans)
- ‚úÖ Materialized views
- ‚úÖ Tiered storage
- ‚úÖ Auto-scaling
- **Budget**: $13,000-15,000/mois ‚≠ê

### Mois 7+: Excellence
- ‚úÖ Multi-r√©gion (DR)
- ‚úÖ ML anomaly detection
- ‚úÖ Self-service analytics
- ‚úÖ Advanced security (RLS)
- **Budget**: $15,000-20,000/mois

## üîÑ Comparaison Alternatives

| Solution | Co√ªt/Mois | Pros | Cons |
|----------|----------:|------|------|
| **Azure Data Explorer** | **$13,465** | ‚≠ê Performance, KQL, Azure natif | Courbe apprentissage KQL |
| Elasticsearch (AKS) | $8,000 | Mature, flexible | Complexit√© op√©rationnelle |
| Elastic Cloud | $15,000 | Manag√© | Co√ªt √©lev√© |
| Splunk Cloud | $30,000+ | Tr√®s mature | Tr√®s cher |
| Datadog Logs | $25,000+ | SaaS simple | Tr√®s cher √† scale |
| AWS OpenSearch | $10,000 | Manag√© AWS | Pas Azure natif |

**Verdict**: ADX = **Meilleur ratio performance/co√ªt** pour Azure + 5TB/jour

## üìã Checklist D√©cision

### ‚úÖ ADX est le bon choix si:
- ‚úÖ Volume > 1 TB/jour
- ‚úÖ Besoin queries complexes et rapides
- ‚úÖ Infrastructure Azure
- ‚úÖ Budget $10,000-20,000/mois OK
- ‚úÖ √âquipe peut apprendre KQL (facile)
- ‚úÖ Besoin streaming temps r√©el

### ‚ö†Ô∏è Consid√©rer alternatives si:
- ‚ùå Volume < 100 GB/jour (Azure Log Analytics suffit)
- ‚ùå Budget < $5,000/mois (Elasticsearch self-hosted)
- ‚ùå D√©j√† investissement lourd Splunk/Elastic
- ‚ùå Queries simples uniquement (grep suffit)
- ‚ùå Pas d'infrastructure Azure

## üìö Documentation Compl√®te

| Document | Description | Pages |
|----------|-------------|-------|
| **[README.md](./README.md)** | Navigation et quick start | üè† |
| **[architecture.md](./architecture.md)** | Architecture globale | üìê |
| **[adx-solution.md](./adx-solution.md)** | D√©tails techniques ADX | üîß |
| **[kql-examples.md](./kql-examples.md)** | 50+ exemples KQL | üìä |
| **[data-ingestion.md](./data-ingestion.md)** | Strat√©gies ingestion | üîÑ |
| **[cost-estimation.md](./cost-estimation.md)** | Analyse financi√®re d√©taill√©e | üí∞ |
| **[diagrams/*.puml](./diagrams/)** | Diagrammes architecture | üé® |

## üéì Ressources d'Apprentissage

### KQL (30 min pour devenir op√©rationnel)
- [KQL Quick Reference](https://docs.microsoft.com/azure/data-explorer/kql-quick-reference)
- [KQL Playground](https://dataexplorer.azure.com/clusters/help/databases/Samples)
- [KQL Tutorial](https://docs.microsoft.com/azure/data-explorer/kusto/query/tutorial)

### ADX
- [ADX Documentation](https://docs.microsoft.com/azure/data-explorer/)
- [Best Practices](https://docs.microsoft.com/azure/data-explorer/best-practices)
- [ADX Web UI](https://dataexplorer.azure.com/)

### Pricing
- [Azure Calculator](https://azure.microsoft.com/pricing/calculator/)
- [ADX Pricing](https://azure.microsoft.com/pricing/details/data-explorer/)

## üèÜ Conclusion

**Pour analyser 5 TB/jour de logs:**

1. **Solution**: Azure Data Explorer avec Event Hubs
2. **Co√ªt**: $13,465/mois optimis√© (RI 3 ans)
3. **Performance**: Sub-seconde queries, <2 min ingestion
4. **ROI**: 3-6 mois
5. **Time to Value**: 30 minutes pour premier cluster

**Recommandation**: ‚≠ê **GO** - Meilleure solution pour ce use case

---

**Next Steps**:
1. ‚úÖ Review cette documentation
2. ‚úÖ Approuver budget (~$15K/mois)
3. ‚úÖ Provisionner environnement pilote ($5K/mois)
4. ‚úÖ Former √©quipe sur KQL (2-3 jours)
5. ‚úÖ Migration progressive (3-6 mois)

**Questions?** Ouvrir une issue dans ce repository.
